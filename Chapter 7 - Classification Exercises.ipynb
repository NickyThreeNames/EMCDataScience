{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(e1071): there is no package called ‘e1071’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(e1071): there is no package called ‘e1071’\nTraceback:\n",
      "1. library(e1071)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a binary classification, describe the possible values of entropy.  On what conditions does entropy reach its minimum and maximum values?\n",
    "\n",
    "Entropy is between 0 and 1.  It reaches its minimum value when the probability of a given class is 0 or 1.  Entropy reaches maximum value when the probability is equal for all classes (ie 50/50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a decision tree, how does the algorithm pick the attributes for splitting?\n",
    "\n",
    "At each step the algorithm looks for the most informative attribute as defined by information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability John has swine flu given the following:\n",
    "\n",
    "1 in 5,000 have it in the US\n",
    "99% accurate\n",
    "1% false positive\n",
    "0% false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.9998"
      ],
      "text/latex": [
       "0.9998"
      ],
      "text/markdown": [
       "0.9998"
      ],
      "text/plain": [
       "[1] 0.9998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1/5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.010196"
      ],
      "text/latex": [
       "0.010196"
      ],
      "text/markdown": [
       "0.010196"
      ],
      "text/plain": [
       "[1] 0.010196"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0002 * .99 + (1 - (1/5000)) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.94193801490781"
      ],
      "text/latex": [
       "1.94193801490781"
      ],
      "text/markdown": [
       "1.94193801490781"
      ],
      "text/plain": [
       "[1] 1.941938"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(.99 * (.0002/0.010196))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which classifier is considered computationally efficient for high-dimensional problems? Why?\n",
    "\n",
    "The naive bayes classifier is very computationally efficient for high level data the calculations are based on countin gthe occurrence of events.  This allows it to handle high dimensional data while running in a straightforward manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data science team is working on a classification problem in which the dataset contains many correlated variables, and most of them are categorical variables.  Which classifier should the team consider using?\n",
    "\n",
    "The team should consider using decision trees.  They are robust to correlated and redundant feactures and easily handle categorical data, even with multiple levels.  These points are especially true to ensembled groups of trees like Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since class probabilities are needed, naive bayes is not the best choice.  Due to the many continuous variables, decision trees are not the best choice either.  I would recommend using a decision tree to identify the most important features (as defined by information gain) and then feed those into a logistic regression model.  Ideally, the correlated variables could be omitted based on information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following confusion matrix (in book):  \n",
    "What are the true positive rate, false positive rate, and false negative rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'TPR = TP/(TP + FN)'"
      ],
      "text/latex": [
       "'TPR = TP/(TP + FN)'"
      ],
      "text/markdown": [
       "'TPR = TP/(TP + FN)'"
      ],
      "text/plain": [
       "[1] \"TPR = TP/(TP + FN)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "'FPR = FP/(FP + TN)'"
      ],
      "text/latex": [
       "'FPR = FP/(FP + TN)'"
      ],
      "text/markdown": [
       "'FPR = FP/(FP + TN)'"
      ],
      "text/plain": [
       "[1] \"FPR = FP/(FP + TN)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "'FNR = FN/(TP + FN)'"
      ],
      "text/latex": [
       "'FNR = FN/(TP + FN)'"
      ],
      "text/markdown": [
       "'FNR = FN/(TP + FN)'"
      ],
      "text/plain": [
       "[1] \"FNR = FN/(TP + FN)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.9585714\n",
      "[1] 0.1266667\n",
      "[1] 0.04142857\n"
     ]
    }
   ],
   "source": [
    "'TPR = TP/(TP + FN)'\n",
    "TPR = 671/700\n",
    "print(TPR)\n",
    "'FPR = FP/(FP + TN)'\n",
    "FPR = 38/ (38 + 262)\n",
    "\n",
    "'FNR = FN/(TP + FN)'\n",
    "FNR = 29/ (29 +671)\n",
    "\n",
    "\n",
    "print(FPR)\n",
    "print(FNR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "r",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
